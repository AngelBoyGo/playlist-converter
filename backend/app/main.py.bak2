import sys
import os
import logging
import asyncio
from datetime import datetime
from typing import List, Optional, Dict, Any
from fastapi import FastAPI, HTTPException, Request, APIRouter
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, FileResponse, HTMLResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel

# Configure logging
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler("app.log")
    ]
)
logger = logging.getLogger(__name__)

# Enhanced import system debugging
logger.info("Starting application...")
logger.info(f"Python version: {sys.version}")
logger.info(f"Current working directory: {os.getcwd()}")
logger.info(f"PYTHONPATH: {sys.path}")

# Add the parent directory to the path if needed
current_dir = os.path.dirname(os.path.abspath(__file__))
backend_dir = os.path.dirname(current_dir)
if backend_dir not in sys.path:
    sys.path.insert(0, backend_dir)
    logger.info(f"Added {backend_dir} to Python path")

# Try different import strategies with detailed error handling
scrape_playlist = None
try:
    # First try relative import from current package
    logger.info("Attempting import from app.scraper.playlist_scraper")
    from app.scraper.playlist_scraper import scrape_playlist
    logger.info("Successfully imported scrape_playlist from app.scraper.playlist_scraper")
except ImportError as e1:
    logger.warning(f"Failed to import from app.scraper.playlist_scraper: {str(e1)}")
    try:
        # Try from relative location
        logger.info("Attempting import from scraper.playlist_scraper")
        from scraper.playlist_scraper import scrape_playlist
        logger.info("Successfully imported scrape_playlist from scraper.playlist_scraper")
    except ImportError as e2:
        logger.warning(f"Failed to import from scraper.playlist_scraper: {str(e2)}")
        try:
            # Try from backend.app.scraper
            logger.info("Attempting import from backend.app.scraper.playlist_scraper")
            from backend.app.scraper.playlist_scraper import scrape_playlist
            logger.info("Successfully imported scrape_playlist from backend.app.scraper.playlist_scraper")
        except ImportError as e3:
            logger.critical(f"All import attempts failed: {str(e3)}")
            # Let's log the directory structure to help debug
            logger.info(f"Directory structure around {current_dir}:")
            for root, dirs, files in os.walk(current_dir, topdown=True, onerror=None):
                for name in dirs:
                    logger.info(f"Directory: {os.path.join(root, name)}")
                for name in files:
                    if name.endswith('.py'):
                        logger.info(f"Python file: {os.path.join(root, name)}")
            raise RuntimeError("Unable to import scrape_playlist function. See logs for details.")

# Import the rest of required modules
try:
    from app.scraper.soundcloud import search_track_on_soundcloud, find_best_match
    from app.routes.debug import router as debug_router
    logger.info("Successfully imported additional modules")
except ImportError as e:
    # Try alternative imports if needed
    logger.error(f"Error importing additional modules: {str(e)}")
    try:
        from scraper.soundcloud import search_track_on_soundcloud, find_best_match
        from routes.debug import router as debug_router
        logger.info("Successfully imported additional modules using alternative paths")
    except ImportError as e2:
        logger.critical(f"Failed to import additional required modules: {str(e2)}")
        raise RuntimeError("Critical import failure. See logs for details.")

# Log system information at startup
logger.info(f"Python executable: {sys.executable}")
logger.info(f"Module search paths: {sys.path}")
logger.info(f"Environment variables: PATH={os.environ.get('PATH', 'Not set')}")
logger.info(f"Chrome env vars: GOOGLE_CHROME_BIN={os.environ.get('GOOGLE_CHROME_BIN', 'Not set')}, CHROMEDRIVER_PATH={os.environ.get('CHROMEDRIVER_PATH', 'Not set')}")

# Define request and response models
class ConversionRequest(BaseModel):
    url: str
    target_platform: str
    start_index: int = 0
    batch_size: int = 5

class Track(BaseModel):
    name: str
    artists: List[str]
    position: int
    url: Optional[str] = None

class ConversionResponse(BaseModel):
    tracks: List[Track]
    total_tracks: int
    playlist_name: str
    source_platform: str
    target_platform: str
    message: Optional[str] = None

class SearchRequest(BaseModel):
    track_name: str
    artist_name: Optional[str] = None
    exclude_current: Optional[bool] = False
    blacklisted_urls: Optional[List[str]] = None

# Initialize the FastAPI app
app = FastAPI(
    title="Playlist Converter API",
    description="Convert playlists between different music streaming platforms",
    version="1.0.0"
)

# Configure CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # In production, you should specify the exact origins
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Include debug routes
app.include_router(debug_router, prefix="/debug", tags=["debug"])

# Mount static files
try:
    app.mount("/static", StaticFiles(directory="static"), name="static")
    app.mount("/", StaticFiles(directory="../frontend", html=True), name="frontend")
    logger.info("Mounted static files successfully")
except Exception as e:
    logger.error(f"Failed to mount static files: {str(e)}")

@app.get("/", response_class=HTMLResponse)
async def get_root():
    """Serve the root HTML file."""
    try:
        with open("../frontend/index.html") as f:
            html_content = f.read()
        return HTMLResponse(content=html_content, status_code=200)
    except Exception as e:
        logger.error(f"Failed to read index.html: {str(e)}")
        return HTMLResponse(content="Internal Server Error", status_code=500)

@app.post("/api/convert", response_model=ConversionResponse)
async def convert_playlist(request: ConversionRequest):
    """Convert a playlist from one platform to another."""
    request_id = datetime.now().strftime("%Y%m%d%H%M%S")
    logger.info(f"[{request_id}] Received conversion request: {request.dict()}")
    
    try:
        # Initialize the playlist scraper
        try:
            # Add detailed logging
            logger.info(f"[{request_id}] About to call scrape_playlist with URL: {request.url}")
            
            if scrape_playlist is None:
                logger.critical(f"[{request_id}] scrape_playlist function not available!")
                raise RuntimeError("scrape_playlist function not properly imported")
                
            # Log function information to help debug
            logger.info(f"[{request_id}] scrape_playlist function ID: {id(scrape_playlist)}")
            logger.info(f"[{request_id}] scrape_playlist module: {scrape_playlist.__module__}")
            
            if hasattr(scrape_playlist, "__code__"):
                logger.info(f"[{request_id}] scrape_playlist signature: {scrape_playlist.__code__.co_varnames[:scrape_playlist.__code__.co_argcount]}")
                logger.info(f"[{request_id}] scrape_playlist required args: {scrape_playlist.__code__.co_argcount - len(scrape_playlist.__defaults__ or ())}")
            
            # Define a wrapper function to ensure correct parameter passing
            async def scrape_with_correct_params(url, start_index=0, batch_size=50):
                """Wrapper to ensure correct parameter passing to scrape_playlist"""
                logger.info(f"[{request_id}] Calling scrape_playlist through wrapper with URL={url}")
                return await scrape_playlist(url=url, start_index=start_index, batch_size=batch_size)
            
            # Call the wrapper function
            logger.info(f"[{request_id}] Calling scrape_playlist wrapper function")
            playlist_data = await scrape_with_correct_params(request.url, request.start_index, request.batch_size)
            logger.info(f"[{request_id}] Successfully scraped playlist: {playlist_data.get('name', 'Unknown')}")
        except Exception as browser_err:
            logger.error(f"[{request_id}] Failed to scrape playlist: {str(browser_err)}", exc_info=True)
            # Additional diagnostic info
            import inspect
            if scrape_playlist is not None:
                logger.info(f"[{request_id}] scrape_playlist source location: {inspect.getfile(scrape_playlist) if inspect.isfunction(scrape_playlist) else 'Not a function'}")
                logger.info(f"[{request_id}] scrape_playlist function details: {inspect.signature(scrape_playlist) if inspect.isfunction(scrape_playlist) else 'Not a function'}")
            raise HTTPException(status_code=500, detail=f"Failed to scrape playlist: {str(browser_err)}")
        
        # Initialize SoundCloud service if needed
        if request.target_platform.lower() == "soundcloud":
            try:
                # Replace SoundCloudService with direct function calls
                soundcloud_browser = await search_track_on_soundcloud(None, None, initialize_only=True)
                logger.info("Successfully initialized SoundCloud service browser")
            except Exception as sc_err:
                logger.error(f"Failed to initialize SoundCloud browser: {str(sc_err)}", exc_info=True)
                raise HTTPException(status_code=500, detail=f"Failed to initialize SoundCloud browser: {str(sc_err)}")
        
        # Get a batch of tracks
        tracks = playlist_data.get("tracks", [])
        start = request.start_index
        end = min(start + request.batch_size, len(tracks))
        batch = tracks[start:end]
        
        # Convert tracks
        converted_tracks = []
        for track in batch:
            try:
                track_name = track.get("name", "").strip()
                artists = track.get("artists", [])
                artist_name = artists[0] if artists else None
                
                # Search for track on target platform
                target_url = None
                if request.target_platform.lower() == "soundcloud" and soundcloud_browser:
                    search_results = await search_track_on_soundcloud(track_name, artist_name, browser=soundcloud_browser)
                    best_match = find_best_match(search_results, track_name, artist_name)
                    if best_match:
                        target_url = best_match.get("url")
                
                # Create track object
                converted_track = Track(
                    name=track_name,
                    artists=artists,
                    position=track.get("position", 0),
                    url=target_url
                )
                converted_tracks.append(converted_track)
                logger.info(f"Converted track: {track_name}")
            except Exception as track_err:
                logger.error(f"Error converting track {track.get('name', 'Unknown')}: {str(track_err)}")
                # Continue with next track rather than failing the whole request
        
        # Clean up SoundCloud browser
        if soundcloud_browser:
            from selenium.webdriver.chrome.webdriver import WebDriver
            if isinstance(soundcloud_browser, WebDriver):
                await asyncio.to_thread(soundcloud_browser.quit)
                logger.info("SoundCloud browser cleaned up successfully")
        
        # Create response
        response = ConversionResponse(
            tracks=converted_tracks,
            total_tracks=len(tracks),
            playlist_name=playlist_data.get("name", "Unknown Playlist"),
            source_platform=playlist_data.get("platform", "Unknown"),
            target_platform=request.target_platform,
            message=f"Converted {len(converted_tracks)} of {len(tracks)} tracks"
        )
        
        return response
    except Exception as e:
        error_msg = f"Error during conversion process: {str(e)}"
        logger.error(error_msg, exc_info=True)
        raise HTTPException(status_code=500, detail=error_msg)

@app.get("/api/health")
async def health_check():
    """Health check endpoint to verify the service is running."""
    return {"status": "ok", "timestamp": datetime.now().isoformat()}

# Search endpoint
@app.post("/api/search")
async def search_track(request: SearchRequest):
    """Search for a track on SoundCloud with support for blacklisting."""
    request_id = datetime.now().strftime("%Y%m%d_%H%M%S")
    logger.info(f"[TRACE][{request_id}] Starting track search: {request.dict()}")
    
    browser = None
    try:
        browser = await search_track_on_soundcloud(None, None, initialize_only=True)
        
        search_results = await search_track_on_soundcloud(
            request.track_name,
            request.artist_name,
            blacklisted_urls=request.blacklisted_urls,
            browser=browser
        )
        
        best_match = find_best_match(search_results, request.track_name, request.artist_name)
        
        if best_match:
            return {
                "success": True,
                "matches": [best_match]
            }
        else:
            return {
                "success": False,
                "message": "No matches found"
            }
            
    except Exception as e:
        logger.error(f"[ERROR][{request_id}] Search failed: {str(e)}", exc_info=True)
        return {
            "success": False,
            "message": f"Search failed: {str(e)}"
        }
    finally:
        if browser:
            from selenium.webdriver.chrome.webdriver import WebDriver
            if isinstance(browser, WebDriver):
                await asyncio.to_thread(browser.quit)
                logger.info("SoundCloud browser cleaned up successfully")

if __name__ == "__main__":
    import uvicorn
    logger.info("Starting server...")
    uvicorn.run(app, host="127.0.0.1", port=8080, log_level="debug") 